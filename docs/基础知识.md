# 什么叫做嵌入层

[代码](book-0to1buildLLM/02-chapter/04-word-embedding.py)
嵌入层(Embedding Layer)是深度学习中的一个重要组件,主要用于将离散的符号(如词语、类别)转换为连续的向量表示。

## 核心概念

嵌入层本质上是一个**查找表**(lookup table),它将每个离散的输入映射到一个固定维度的稠密向量。比如:

- 词 "猫" → [0.2, -0.5, 0.8, ...]
- 词 "狗" → [0.3, -0.4, 0.7, ...]

## 为什么需要嵌入层?

1. **降维**: 独热编码(one-hot)对于大词汇表会产生非常高维且稀疏的向量,嵌入层可以将其压缩到较低维度的稠密向量

2. **学习语义关系**: 通过训练,相似含义的词会获得相近的向量表示,比如"国王-男人+女人 ≈ 王后"

3. **参数效率**: 相比直接处理原始离散数据,嵌入向量更适合神经网络处理

## 典型应用

- **NLP**: Word2Vec、GloVe 等词嵌入
- **推荐系统**: 用户 ID、商品 ID 的嵌入
- **分类任务**: 类别特征的嵌入

## 简单示例

```python
import torch.nn as nn

# 词汇表大小1000,嵌入维度128
embedding = nn.Embedding(num_embeddings=1000, embedding_dim=128)

# 输入词的索引 [5, 23, 100]
input_ids = torch.LongTensor([5, 23, 100])

# 输出形状: [3, 128]
output = embedding(input_ids)
```

嵌入层的权重在训练过程中会不断优化,以更好地表示数据的语义特征。
